{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a847765c-f6ad-400b-89ee-fb0316b7f794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dataset Overview ===\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "  species  \n",
      "0  setosa  \n",
      "1  setosa  \n",
      "2  setosa  \n",
      "3  setosa  \n",
      "4  setosa  \n",
      "\n",
      "=== Dataset Information ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   sepal length (cm)  150 non-null    float64\n",
      " 1   sepal width (cm)   150 non-null    float64\n",
      " 2   petal length (cm)  150 non-null    float64\n",
      " 3   petal width (cm)   150 non-null    float64\n",
      " 4   species            150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "None\n",
      "\n",
      "=== Statistical Summary ===\n",
      "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
      "count         150.000000        150.000000         150.000000   \n",
      "mean            5.843333          3.057333           3.758000   \n",
      "std             0.828066          0.435866           1.765298   \n",
      "min             4.300000          2.000000           1.000000   \n",
      "25%             5.100000          2.800000           1.600000   \n",
      "50%             5.800000          3.000000           4.350000   \n",
      "75%             6.400000          3.300000           5.100000   \n",
      "max             7.900000          4.400000           6.900000   \n",
      "\n",
      "       petal width (cm)  \n",
      "count        150.000000  \n",
      "mean           1.199333  \n",
      "std            0.762238  \n",
      "min            0.100000  \n",
      "25%            0.300000  \n",
      "50%            1.300000  \n",
      "75%            1.800000  \n",
      "max            2.500000  \n",
      "\n",
      "=== Class Distribution ===\n",
      "species\n",
      "setosa        50\n",
      "versicolor    50\n",
      "virginica     50\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Creating pairplot...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1075: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1075: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1075: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1075: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1075: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1075: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1075: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1075: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1075: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1075: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1075: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "C:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1075: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression ===\n",
      "Accuracy: 0.9333\n",
      "Cross-validation scores: [0.91666667 0.95833333 0.95833333 0.95833333 1.        ]\n",
      "Mean CV accuracy: 0.9583\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       0.90      0.90      0.90        10\n",
      "   virginica       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.93      0.93      0.93        30\n",
      "weighted avg       0.93      0.93      0.93        30\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  1]\n",
      " [ 0  1  9]]\n",
      "\n",
      "=== K-Nearest Neighbors ===\n",
      "Accuracy: 0.9333\n",
      "Cross-validation scores: [0.91666667 1.         0.95833333 0.95833333 1.        ]\n",
      "Mean CV accuracy: 0.9667\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       0.83      1.00      0.91        10\n",
      "   virginica       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.94      0.93      0.93        30\n",
      "weighted avg       0.94      0.93      0.93        30\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  2  8]]\n",
      "\n",
      "=== Support Vector Machine ===\n",
      "Accuracy: 0.9667\n",
      "Cross-validation scores: [0.91666667 1.         0.95833333 0.95833333 1.        ]\n",
      "Mean CV accuracy: 0.9667\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      0.90      0.95        10\n",
      "   virginica       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  1]\n",
      " [ 0  0 10]]\n",
      "\n",
      "=== Decision Tree ===\n",
      "Accuracy: 0.9667\n",
      "Cross-validation scores: [0.91666667 0.95833333 0.95833333 0.95833333 0.91666667]\n",
      "Mean CV accuracy: 0.9417\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      0.90      0.95        10\n",
      "   virginica       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  1]\n",
      " [ 0  0 10]]\n",
      "\n",
      "=== Random Forest ===\n",
      "Accuracy: 0.9333\n",
      "Cross-validation scores: [0.91666667 0.95833333 0.95833333 0.95833333 0.95833333]\n",
      "Mean CV accuracy: 0.9500\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       0.90      0.90      0.90        10\n",
      "   virginica       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.93      0.93      0.93        30\n",
      "weighted avg       0.93      0.93      0.93        30\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  1]\n",
      " [ 0  1  9]]\n",
      "\n",
      "Best Model: Support Vector Machine with accuracy 0.9667\n",
      "\n",
      "=== Model Training and Evaluation Complete ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "feature_names = iris.feature_names\n",
    "target_names = iris.target_names\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "iris_df = pd.DataFrame(X, columns=feature_names)\n",
    "iris_df['species'] = y\n",
    "iris_df['species'] = iris_df['species'].map({0: target_names[0], 1: target_names[1], 2: target_names[2]})\n",
    "\n",
    "# Data Exploration\n",
    "print(\"=== Dataset Overview ===\")\n",
    "print(iris_df.head())\n",
    "print(\"\\n=== Dataset Information ===\")\n",
    "print(iris_df.info())\n",
    "print(\"\\n=== Statistical Summary ===\")\n",
    "print(iris_df.describe())\n",
    "print(\"\\n=== Class Distribution ===\")\n",
    "print(iris_df['species'].value_counts())\n",
    "\n",
    "# Visualizations\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Pairplot to see relationships between features\n",
    "print(\"\\nCreating pairplot...\")\n",
    "sns.pairplot(iris_df, hue='species', markers=['o', 's', 'D'])\n",
    "plt.suptitle('Pairplot of Iris Features by Species', y=1.02)\n",
    "plt.savefig('iris_pairplot.png')\n",
    "plt.close()\n",
    "\n",
    "# Boxplots for each feature by species\n",
    "plt.figure(figsize=(15, 8))\n",
    "for i, feature in enumerate(feature_names):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    sns.boxplot(x='species', y=feature, data=iris_df)\n",
    "    plt.title(f'Distribution of {feature} by Species')\n",
    "plt.tight_layout()\n",
    "plt.savefig('iris_boxplots.png')\n",
    "plt.close()\n",
    "\n",
    "# Correlation matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "corr_matrix = iris_df.iloc[:, :4].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.savefig('iris_correlation.png')\n",
    "plt.close()\n",
    "\n",
    "# Data Preprocessing\n",
    "# Split into features and target\n",
    "X = iris_df.iloc[:, :4].values\n",
    "y = iris_df['species'].values\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Model Selection and Training\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=200),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Support Vector Machine': SVC(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier()\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, target_names=target_names)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'report': report,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)\n",
    "    \n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Cross-validation scores: {cv_scores}\")\n",
    "    print(f\"Mean CV accuracy: {np.mean(cv_scores):.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "# Find the best model\n",
    "best_model_name = max(results, key=lambda x: results[x]['accuracy'])\n",
    "best_model = results[best_model_name]['model']\n",
    "print(f\"\\nBest Model: {best_model_name} with accuracy {results[best_model_name]['accuracy']:.4f}\")\n",
    "\n",
    "# Feature Importance Analysis\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    # For tree-based models\n",
    "    importances = best_model.feature_importances_\n",
    "elif hasattr(best_model, 'coef_'):\n",
    "    # For linear models\n",
    "    importances = np.abs(best_model.coef_).mean(axis=0)\n",
    "else:\n",
    "    # For models without direct feature importance\n",
    "    importances = None\n",
    "\n",
    "if importances is not None:\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importances\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='Importance', y='Feature', data=feature_importance)\n",
    "    plt.title('Feature Importance for Species Classification')\n",
    "    plt.savefig('feature_importance.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"\\n=== Feature Importance ===\")\n",
    "    print(feature_importance)\n",
    "\n",
    "# Save the best model (optional)\n",
    "import joblib\n",
    "joblib.dump(best_model, 'best_iris_model.pkl')\n",
    "joblib.dump(scaler, 'iris_scaler.pkl')\n",
    "\n",
    "print(\"\\n=== Model Training and Evaluation Complete ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbc9ac7-6c0b-47bc-94fc-bbc0b7723596",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
